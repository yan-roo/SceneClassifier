{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Store',\n",
       " 'LivingRoom',\n",
       " 'Coast',\n",
       " 'OpenCountry',\n",
       " 'Street',\n",
       " 'Forest',\n",
       " 'Office',\n",
       " 'TallBuilding',\n",
       " 'Highway',\n",
       " 'Kitchen',\n",
       " 'InsideCity',\n",
       " 'Suburb',\n",
       " 'Mountain',\n",
       " 'Industrial',\n",
       " 'Bedroom']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import PIL\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(device=gpu, enable=True)\n",
    "\n",
    "os.listdir(f'hw5_data/train/')  # Directory where training data folders are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Training batch size\n",
    "num_classes = 15  # Classes in dataset\n",
    "num_epochs = 40   # Epochs for training   \n",
    "lr = 1e-3  # Learning rate\n",
    "lr_weight_decay = 1e-3 # Learning weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 15 classes.\n",
      "Found 150 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\"\"\"\n",
    "from albumentations.augmentations.transforms import Rotate\n",
    "from albumentations import Compose\n",
    "\n",
    "def augment_and_show(image):\n",
    "    #image = Equalize(mode='pil', always_apply=True, p=1)(image=np.array(image).astype('uint8'))['image']\n",
    "    aug = Compose([Rotate(limit=5, interpolation=2, p=1)])\n",
    "    image = aug(image=image)['image']\n",
    "    return image.astype('float')\n",
    "\"\"\"\n",
    "\n",
    "# preprocessing image and divide validaiton set\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True, brightness_range=[0.5,1.5], zoom_range=[0.8,1])\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('hw5_data/train/',\n",
    "                                                 target_size=(256,256),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='sparse',\n",
    "                                                 shuffle=True,\n",
    "                                                 subset='training')\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory('hw5_data/test/',target_size=(256,256),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='sparse')\n",
    "\n",
    "\n",
    "# for i in range(25):\n",
    "#     plt.figure(figsize=(30,20))\n",
    "#     plt.subplot(5,5,i+1)\n",
    "#     plt.imshow(train_generator.next()[0][i].astype('uint8'))\n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 256, 256, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 262, 262, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 128, 128, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 128, 128, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 128, 128, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 130, 130, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 64, 64, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 64, 64, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 64, 64, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn3 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu3 (Activation) (None, 64, 64, 64)   0           stage1_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv3 (Conv2D)     (None, 64, 64, 256)  16384       stage1_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 64, 64, 256)  16384       stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 64, 256)  0           stage1_unit1_conv3[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 64, 64, 256)  1024        add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 64, 64, 256)  0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 64, 64, 64)   16384       stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn3 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu3 (Activation) (None, 64, 64, 64)   0           stage1_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv3 (Conv2D)     (None, 64, 64, 256)  16384       stage1_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 256)  0           stage1_unit2_conv3[0][0]         \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 64, 64, 256)  1024        add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 64, 64, 256)  0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 64, 64, 64)   16384       stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 66, 66, 64)   0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 64, 64, 64)   36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn3 (BatchNormaliz (None, 64, 64, 64)   256         stage1_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu3 (Activation) (None, 64, 64, 64)   0           stage1_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv3 (Conv2D)     (None, 64, 64, 256)  16384       stage1_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 256)  0           stage1_unit3_conv3[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 64, 64, 256)  1024        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 64, 64, 256)  0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 64, 64, 128)  32768       stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 64, 64, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 64, 64, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 66, 66, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn3 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu3 (Activation) (None, 32, 32, 128)  0           stage2_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv3 (Conv2D)     (None, 32, 32, 512)  65536       stage2_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 32, 32, 512)  131072      stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 512)  0           stage2_unit1_conv3[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 32, 32, 512)  2048        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 32, 32, 512)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 32, 32, 128)  65536       stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn3 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu3 (Activation) (None, 32, 32, 128)  0           stage2_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv3 (Conv2D)     (None, 32, 32, 512)  65536       stage2_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 512)  0           stage2_unit2_conv3[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 32, 32, 512)  2048        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 32, 32, 512)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 32, 32, 128)  65536       stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn3 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu3 (Activation) (None, 32, 32, 128)  0           stage2_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv3 (Conv2D)     (None, 32, 32, 512)  65536       stage2_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 512)  0           stage2_unit3_conv3[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 32, 32, 512)  2048        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 32, 32, 512)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 32, 32, 128)  65536       stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 34, 34, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 32, 32, 128)  147456      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn3 (BatchNormaliz (None, 32, 32, 128)  512         stage2_unit4_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu3 (Activation) (None, 32, 32, 128)  0           stage2_unit4_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv3 (Conv2D)     (None, 32, 32, 512)  65536       stage2_unit4_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, 32, 512)  0           stage2_unit4_conv3[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 32, 32, 512)  2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 32, 32, 512)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 32, 32, 256)  131072      stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 32, 32, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 32, 32, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 34, 34, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn3 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu3 (Activation) (None, 16, 16, 256)  0           stage3_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv3 (Conv2D)     (None, 16, 16, 1024) 262144      stage3_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 16, 16, 1024) 524288      stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 1024) 0           stage3_unit1_conv3[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 16, 16, 1024) 4096        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 16, 16, 1024) 0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 16, 16, 256)  262144      stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn3 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu3 (Activation) (None, 16, 16, 256)  0           stage3_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv3 (Conv2D)     (None, 16, 16, 1024) 262144      stage3_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 1024) 0           stage3_unit2_conv3[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 16, 16, 1024) 4096        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 16, 16, 1024) 0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 16, 16, 256)  262144      stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn3 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu3 (Activation) (None, 16, 16, 256)  0           stage3_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv3 (Conv2D)     (None, 16, 16, 1024) 262144      stage3_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 1024) 0           stage3_unit3_conv3[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 16, 16, 1024) 4096        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 16, 16, 1024) 0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 16, 16, 256)  262144      stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn3 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit4_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu3 (Activation) (None, 16, 16, 256)  0           stage3_unit4_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv3 (Conv2D)     (None, 16, 16, 1024) 262144      stage3_unit4_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 1024) 0           stage3_unit4_conv3[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 16, 16, 1024) 4096        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 16, 16, 1024) 0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 16, 16, 256)  262144      stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn3 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit5_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu3 (Activation) (None, 16, 16, 256)  0           stage3_unit5_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv3 (Conv2D)     (None, 16, 16, 1024) 262144      stage3_unit5_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 1024) 0           stage3_unit5_conv3[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 16, 16, 1024) 4096        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 16, 16, 1024) 0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 16, 16, 256)  262144      stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 18, 18, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 16, 16, 256)  589824      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn3 (BatchNormaliz (None, 16, 16, 256)  1024        stage3_unit6_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu3 (Activation) (None, 16, 16, 256)  0           stage3_unit6_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv3 (Conv2D)     (None, 16, 16, 1024) 262144      stage3_unit6_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 16, 16, 1024) 0           stage3_unit6_conv3[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 16, 16, 1024) 4096        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 16, 16, 1024) 0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 16, 16, 512)  524288      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 16, 16, 512)  2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 16, 16, 512)  0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 18, 18, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn3 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit1_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu3 (Activation) (None, 8, 8, 512)    0           stage4_unit1_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv3 (Conv2D)     (None, 8, 8, 2048)   1048576     stage4_unit1_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 8, 8, 2048)   2097152     stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 2048)   0           stage4_unit1_conv3[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 8, 8, 2048)   8192        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 8, 8, 2048)   0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 8, 8, 512)    1048576     stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn3 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit2_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu3 (Activation) (None, 8, 8, 512)    0           stage4_unit2_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv3 (Conv2D)     (None, 8, 8, 2048)   1048576     stage4_unit2_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 2048)   0           stage4_unit2_conv3[0][0]         \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 8, 8, 2048)   8192        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 8, 8, 2048)   0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 8, 8, 512)    1048576     stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 8, 8, 512)    2359296     zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn3 (BatchNormaliz (None, 8, 8, 512)    2048        stage4_unit3_conv2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu3 (Activation) (None, 8, 8, 512)    0           stage4_unit3_bn3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv3 (Conv2D)     (None, 8, 8, 2048)   1048576     stage4_unit3_relu3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 2048)   0           stage4_unit3_conv3[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 8, 8, 2048)   8192        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 8, 8, 2048)   0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 15)           30735       global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 23,576,792\n",
      "Trainable params: 23,273,231\n",
      "Non-trainable params: 303,561\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from classification_models.tfkeras import Classifiers\n",
    "\n",
    "ResNet50, preprocess_input = Classifiers.get('resnet50')\n",
    "base_model = ResNet50(input_shape=(256, 256, 3), weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "output = Dense(num_classes, kernel_initializer='zeros')(x)\n",
    "model = Model(inputs=[base_model.input], outputs=[output])\n",
    "\n",
    "\n",
    "# Training with the final custom-made layers\n",
    "# ResNet 50 (48,51)\n",
    "for layer in model.layers[:48]:\n",
    "    layer.trainable =False\n",
    "    \n",
    "        \n",
    "for layer in model.layers[48:]:\n",
    "    layer.trainable=True\n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "class CosineAnnealingScheduler(Callback):\n",
    "    \"\"\"Cosine annealing scheduler.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, T_max, eta_max, eta_min=0, verbose=1):\n",
    "        super(CosineAnnealingScheduler, self).__init__()\n",
    "        self.T_max = T_max\n",
    "        self.eta_max = eta_max\n",
    "        self.eta_min = eta_min\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        lr = self.eta_min + (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * epoch / self.T_max)) / 2\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        if self.verbose > 0:\n",
    "            print('\\nEpoch %05d: CosineAnnealingScheduler setting learning '\n",
    "                  'rate to %s.' % (epoch + 1, lr))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "        \n",
    "cosineanneling = CosineAnnealingScheduler(T_max=5, eta_max=1e-2, eta_min=1e-5)\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint('logs/ep{epoch:03}-val_loss{val_loss:.3f}.h5', save_best_only=False, save_weight_only=True, monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-2f899f0a9964>:16: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "\n",
      "Epoch 00001: CosineAnnealingScheduler setting learning rate to 0.01.\n",
      "Epoch 1/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.5945 - accuracy: 0.5577\n",
      "Epoch 00001: saving model to logs/ep001-val_loss0.708.h5\n",
      "23/23 [==============================] - 17s 740ms/step - loss: 1.5945 - accuracy: 0.5577 - val_loss: 0.7085 - val_accuracy: 0.7109 - lr: 0.0100\n",
      "\n",
      "Epoch 00002: CosineAnnealingScheduler setting learning rate to 0.009046039886902862.\n",
      "Epoch 2/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2974 - accuracy: 0.8990\n",
      "Epoch 00002: saving model to logs/ep002-val_loss0.565.h5\n",
      "23/23 [==============================] - 16s 715ms/step - loss: 0.2974 - accuracy: 0.8990 - val_loss: 0.5652 - val_accuracy: 0.7969 - lr: 0.0090\n",
      "\n",
      "Epoch 00003: CosineAnnealingScheduler setting learning rate to 0.006548539886902863.\n",
      "Epoch 3/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.9492\n",
      "Epoch 00003: saving model to logs/ep003-val_loss0.903.h5\n",
      "23/23 [==============================] - 16s 712ms/step - loss: 0.1484 - accuracy: 0.9492 - val_loss: 0.9026 - val_accuracy: 0.7422 - lr: 0.0065\n",
      "\n",
      "Epoch 00004: CosineAnnealingScheduler setting learning rate to 0.0034614601130971384.\n",
      "Epoch 4/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9854\n",
      "Epoch 00004: saving model to logs/ep004-val_loss0.340.h5\n",
      "23/23 [==============================] - 16s 715ms/step - loss: 0.0658 - accuracy: 0.9854 - val_loss: 0.3398 - val_accuracy: 0.8750 - lr: 0.0035\n",
      "\n",
      "Epoch 00005: CosineAnnealingScheduler setting learning rate to 0.0009639601130971381.\n",
      "Epoch 5/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9923\n",
      "Epoch 00005: saving model to logs/ep005-val_loss0.199.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0388 - accuracy: 0.9923 - val_loss: 0.1994 - val_accuracy: 0.9297 - lr: 9.6396e-04\n",
      "\n",
      "Epoch 00006: CosineAnnealingScheduler setting learning rate to 1e-05.\n",
      "Epoch 6/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9896\n",
      "Epoch 00006: saving model to logs/ep006-val_loss0.207.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0383 - accuracy: 0.9896 - val_loss: 0.2067 - val_accuracy: 0.9453 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 00007: CosineAnnealingScheduler setting learning rate to 0.000963960113097137.\n",
      "Epoch 7/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9889\n",
      "Epoch 00007: saving model to logs/ep007-val_loss0.197.h5\n",
      "23/23 [==============================] - 16s 711ms/step - loss: 0.0427 - accuracy: 0.9889 - val_loss: 0.1974 - val_accuracy: 0.9297 - lr: 9.6396e-04\n",
      "\n",
      "Epoch 00008: CosineAnnealingScheduler setting learning rate to 0.003461460113097137.\n",
      "Epoch 8/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9916\n",
      "Epoch 00008: saving model to logs/ep008-val_loss0.151.h5\n",
      "23/23 [==============================] - 16s 713ms/step - loss: 0.0353 - accuracy: 0.9916 - val_loss: 0.1512 - val_accuracy: 0.9375 - lr: 0.0035\n",
      "\n",
      "Epoch 00009: CosineAnnealingScheduler setting learning rate to 0.006548539886902862.\n",
      "Epoch 9/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9944\n",
      "Epoch 00009: saving model to logs/ep009-val_loss0.120.h5\n",
      "23/23 [==============================] - 16s 710ms/step - loss: 0.0287 - accuracy: 0.9944 - val_loss: 0.1199 - val_accuracy: 0.9609 - lr: 0.0065\n",
      "\n",
      "Epoch 00010: CosineAnnealingScheduler setting learning rate to 0.009046039886902862.\n",
      "Epoch 10/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9965\n",
      "Epoch 00010: saving model to logs/ep010-val_loss0.162.h5\n",
      "23/23 [==============================] - 16s 715ms/step - loss: 0.0298 - accuracy: 0.9965 - val_loss: 0.1615 - val_accuracy: 0.9297 - lr: 0.0090\n",
      "\n",
      "Epoch 00011: CosineAnnealingScheduler setting learning rate to 0.01.\n",
      "Epoch 11/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9951\n",
      "Epoch 00011: saving model to logs/ep011-val_loss0.219.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0211 - accuracy: 0.9951 - val_loss: 0.2190 - val_accuracy: 0.9141 - lr: 0.0100\n",
      "\n",
      "Epoch 00012: CosineAnnealingScheduler setting learning rate to 0.009046039886902866.\n",
      "Epoch 12/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9972\n",
      "Epoch 00012: saving model to logs/ep012-val_loss0.158.h5\n",
      "23/23 [==============================] - 16s 713ms/step - loss: 0.0173 - accuracy: 0.9972 - val_loss: 0.1580 - val_accuracy: 0.9531 - lr: 0.0090\n",
      "\n",
      "Epoch 00013: CosineAnnealingScheduler setting learning rate to 0.006548539886902864.\n",
      "Epoch 13/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9979\n",
      "Epoch 00013: saving model to logs/ep013-val_loss0.186.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0188 - accuracy: 0.9979 - val_loss: 0.1863 - val_accuracy: 0.9375 - lr: 0.0065\n",
      "\n",
      "Epoch 00014: CosineAnnealingScheduler setting learning rate to 0.0034614601130971393.\n",
      "Epoch 14/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9986\n",
      "Epoch 00014: saving model to logs/ep014-val_loss0.145.h5\n",
      "23/23 [==============================] - 16s 713ms/step - loss: 0.0107 - accuracy: 0.9986 - val_loss: 0.1451 - val_accuracy: 0.9531 - lr: 0.0035\n",
      "\n",
      "Epoch 00015: CosineAnnealingScheduler setting learning rate to 0.0009639601130971387.\n",
      "Epoch 15/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9972\n",
      "Epoch 00015: saving model to logs/ep015-val_loss0.158.h5\n",
      "23/23 [==============================] - 16s 716ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.1582 - val_accuracy: 0.9453 - lr: 9.6396e-04\n",
      "\n",
      "Epoch 00016: CosineAnnealingScheduler setting learning rate to 1e-05.\n",
      "Epoch 16/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 00016: saving model to logs/ep016-val_loss0.162.h5\n",
      "23/23 [==============================] - 16s 712ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1624 - val_accuracy: 0.9375 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 00017: CosineAnnealingScheduler setting learning rate to 0.0009639601130971365.\n",
      "Epoch 17/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 00017: saving model to logs/ep017-val_loss0.141.h5\n",
      "23/23 [==============================] - 16s 710ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9453 - lr: 9.6396e-04\n",
      "\n",
      "Epoch 00018: CosineAnnealingScheduler setting learning rate to 0.0034614601130971354.\n",
      "Epoch 18/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 00018: saving model to logs/ep018-val_loss0.133.h5\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1328 - val_accuracy: 0.9531 - lr: 0.0035\n",
      "\n",
      "Epoch 00019: CosineAnnealingScheduler setting learning rate to 0.00654853988690286.\n",
      "Epoch 19/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9993\n",
      "Epoch 00019: saving model to logs/ep019-val_loss0.141.h5\n",
      "23/23 [==============================] - 16s 713ms/step - loss: 0.0075 - accuracy: 0.9993 - val_loss: 0.1407 - val_accuracy: 0.9453 - lr: 0.0065\n",
      "\n",
      "Epoch 00020: CosineAnnealingScheduler setting learning rate to 0.00904603988690286.\n",
      "Epoch 20/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 00020: saving model to logs/ep020-val_loss0.159.h5\n",
      "23/23 [==============================] - 16s 715ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 0.9453 - lr: 0.0090\n",
      "\n",
      "Epoch 00021: CosineAnnealingScheduler setting learning rate to 0.01.\n",
      "Epoch 21/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 00021: saving model to logs/ep021-val_loss0.160.h5\n",
      "23/23 [==============================] - 17s 735ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1600 - val_accuracy: 0.9531 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: CosineAnnealingScheduler setting learning rate to 0.009046039886902864.\n",
      "Epoch 22/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 00022: saving model to logs/ep022-val_loss0.163.h5\n",
      "23/23 [==============================] - 17s 748ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9453 - lr: 0.0090\n",
      "\n",
      "Epoch 00023: CosineAnnealingScheduler setting learning rate to 0.006548539886902874.\n",
      "Epoch 23/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 00023: saving model to logs/ep023-val_loss0.164.h5\n",
      "23/23 [==============================] - 16s 717ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1635 - val_accuracy: 0.9453 - lr: 0.0065\n",
      "\n",
      "Epoch 00024: CosineAnnealingScheduler setting learning rate to 0.0034614601130971406.\n",
      "Epoch 24/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 00024: saving model to logs/ep024-val_loss0.135.h5\n",
      "23/23 [==============================] - 16s 707ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.1353 - val_accuracy: 0.9609 - lr: 0.0035\n",
      "\n",
      "Epoch 00025: CosineAnnealingScheduler setting learning rate to 0.0009639601130971392.\n",
      "Epoch 25/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 00025: saving model to logs/ep025-val_loss0.157.h5\n",
      "23/23 [==============================] - 17s 733ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9453 - lr: 9.6396e-04\n",
      "\n",
      "Epoch 00026: CosineAnnealingScheduler setting learning rate to 1e-05.\n",
      "Epoch 26/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9993\n",
      "Epoch 00026: saving model to logs/ep026-val_loss0.144.h5\n",
      "23/23 [==============================] - 17s 740ms/step - loss: 0.0070 - accuracy: 0.9993 - val_loss: 0.1440 - val_accuracy: 0.9531 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 00027: CosineAnnealingScheduler setting learning rate to 0.0009639601130971359.\n",
      "Epoch 27/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 00027: saving model to logs/ep027-val_loss0.119.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9609 - lr: 9.6396e-04\n",
      "\n",
      "Epoch 00028: CosineAnnealingScheduler setting learning rate to 0.0034614601130971345.\n",
      "Epoch 28/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9986\n",
      "Epoch 00028: saving model to logs/ep028-val_loss0.146.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.1459 - val_accuracy: 0.9531 - lr: 0.0035\n",
      "\n",
      "Epoch 00029: CosineAnnealingScheduler setting learning rate to 0.006548539886902859.\n",
      "Epoch 29/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 00029: saving model to logs/ep029-val_loss0.193.h5\n",
      "23/23 [==============================] - 16s 716ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1929 - val_accuracy: 0.9453 - lr: 0.0065\n",
      "\n",
      "Epoch 00030: CosineAnnealingScheduler setting learning rate to 0.00904603988690286.\n",
      "Epoch 30/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 00030: saving model to logs/ep030-val_loss0.160.h5\n",
      "23/23 [==============================] - 16s 716ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1605 - val_accuracy: 0.9531 - lr: 0.0090\n",
      "\n",
      "Epoch 00031: CosineAnnealingScheduler setting learning rate to 0.01.\n",
      "Epoch 31/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 00031: saving model to logs/ep031-val_loss0.176.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9531 - lr: 0.0100\n",
      "\n",
      "Epoch 00032: CosineAnnealingScheduler setting learning rate to 0.009046039886902864.\n",
      "Epoch 32/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9993\n",
      "Epoch 00032: saving model to logs/ep032-val_loss0.213.h5\n",
      "23/23 [==============================] - 16s 717ms/step - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.2134 - val_accuracy: 0.9219 - lr: 0.0090\n",
      "\n",
      "Epoch 00033: CosineAnnealingScheduler setting learning rate to 0.006548539886902866.\n",
      "Epoch 33/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 00033: saving model to logs/ep033-val_loss0.226.h5\n",
      "23/23 [==============================] - 16s 717ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2264 - val_accuracy: 0.8984 - lr: 0.0065\n",
      "\n",
      "Epoch 00034: CosineAnnealingScheduler setting learning rate to 0.0034614601130971414.\n",
      "Epoch 34/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9993\n",
      "Epoch 00034: saving model to logs/ep034-val_loss0.185.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.1851 - val_accuracy: 0.9141 - lr: 0.0035\n",
      "\n",
      "Epoch 00035: CosineAnnealingScheduler setting learning rate to 0.0009639601130971403.\n",
      "Epoch 35/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9993\n",
      "Epoch 00035: saving model to logs/ep035-val_loss0.200.h5\n",
      "23/23 [==============================] - 16s 715ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.1998 - val_accuracy: 0.9141 - lr: 9.6396e-04\n",
      "\n",
      "Epoch 00036: CosineAnnealingScheduler setting learning rate to 1e-05.\n",
      "Epoch 36/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 00036: saving model to logs/ep036-val_loss0.207.h5\n",
      "23/23 [==============================] - 16s 713ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9219 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 00037: CosineAnnealingScheduler setting learning rate to 0.0009639601130971353.\n",
      "Epoch 37/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9993\n",
      "Epoch 00037: saving model to logs/ep037-val_loss0.214.h5\n",
      "23/23 [==============================] - 16s 715ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.2139 - val_accuracy: 0.9141 - lr: 9.6396e-04\n",
      "\n",
      "Epoch 00038: CosineAnnealingScheduler setting learning rate to 0.003461460113097133.\n",
      "Epoch 38/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9993\n",
      "Epoch 00038: saving model to logs/ep038-val_loss0.215.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.2145 - val_accuracy: 0.9219 - lr: 0.0035\n",
      "\n",
      "Epoch 00039: CosineAnnealingScheduler setting learning rate to 0.006548539886902858.\n",
      "Epoch 39/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 00039: saving model to logs/ep039-val_loss0.179.h5\n",
      "23/23 [==============================] - 16s 714ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1789 - val_accuracy: 0.9297 - lr: 0.0065\n",
      "\n",
      "Epoch 00040: CosineAnnealingScheduler setting learning rate to 0.00904603988690286.\n",
      "Epoch 40/40\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9993\n",
      "Epoch 00040: saving model to logs/ep040-val_loss0.142.h5\n",
      "23/23 [==============================] - 16s 713ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.1415 - val_accuracy: 0.9375 - lr: 0.0090\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "# Use default adam optimizer (learning rate=1e-3, decay=0)\n",
    "# Loss function: categorical cross entropy\n",
    "# Evaluation: Accuracy\n",
    "\n",
    "sgd = optimizers.SGD(lr=1e-3, momentum=0.9, decay=1e-3)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=sgd, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "step_size_val = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "history = model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train,\n",
    "                              validation_data=validation_generator, validation_steps=step_size_val,\n",
    "                              epochs=num_epochs , callbacks=[cosineanneling, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "# import efficientnet.tfkeras as efn \n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import optimizers\n",
    "\n",
    "# def get_compiled_model():\n",
    "\n",
    "#     base_model = efn.EfficientNetB0(input_shape=(256, 256, 3), weights='imagenet', include_top=False)  # or weights='noisy-student'\n",
    "#     x = GlobalAveragePooling2D()(base_model.output)\n",
    "#     output = Dense(num_classes, activation='softmax')(x)\n",
    "#     model = Model(inputs=[base_model.input], outputs=[output])\n",
    "    \n",
    "# #     for layer in model.layers[:22]:\n",
    "# #         layer.trainable =False\n",
    "\n",
    "# #     for layer in model.layers[22:]:\n",
    "# #         layer.trainable=True\n",
    "\n",
    "#     sgd = optimizers.SGD(lr=1e-3, momentum=0.9, decay=1e-3)\n",
    "#     model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "# print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "\n",
    "\n",
    "# step_size_train = train_generator.n // train_generator.batch_size\n",
    "# step_size_val = validation_generator.n // validation_generator.batch_size\n",
    "\n",
    "\n",
    "# with strategy.scope():\n",
    "#   # Everything that creates variables should be under the strategy scope.\n",
    "#   # In general this is only model construction & `compile()`.\n",
    "#     model = get_compiled_model()\n",
    "   \n",
    "    \n",
    "# history = model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train,\n",
    "#                               validation_data=validation_generator, validation_steps=step_size_val,\n",
    "#                               epochs=num_epochs , callbacks=[cosineanneling, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('ResNet50 Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('ResNet50 Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label =  os.listdir(f'hw5_data/train/')\n",
    "\n",
    "def DataLoader(path, standardize=False):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    num_img = 0\n",
    "    for classes in class_label:\n",
    "        for img in os.listdir(f'hw5_data/{path}/{classes}'):\n",
    "            if img.endswith('.jpg'):\n",
    "                label_list.append(classes)\n",
    "                original = cv2.imread(f'hw5_data/{path}/{classes}/{img}')\n",
    "                \n",
    "\n",
    "                #original = augment_and_show(original)\n",
    "                resized_img = cv2.resize(original, (256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                img_list.append(resized_img)\n",
    "                num_img += 1\n",
    "    #img_list = img_list.T[1:,:]\n",
    "    return np.array(img_list), label_list, num_img\n",
    "\n",
    "\n",
    "test_img, test_label, num_test = DataLoader('test', standardize=False)\n",
    "\n",
    "dic = train_generator.class_indices\n",
    "label_num = []\n",
    "\n",
    "for label in test_label:\n",
    "    label_num.append(dic[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#B0 imagenet batch_size 64 0.92(rand) -> nosiey 0.906\n",
    "#B1 imagenet batch_size 64 0.926(rand) -> nosiey 0.906\n",
    "\n",
    "#B4 imagenet batch_size 16 0.92 -> 0.946(flip)\n",
    "\n",
    "#B4 imagenet batch_size 32 0.95\n",
    "#B4 imagenet batch_size 32 0.89 layer1\n",
    "#B4 imagenet batch_size 32 0.9 layer2\n",
    "\n",
    "#B5 imagenet batch_size 16 0.926\n",
    "#B6 imagenet batch_size 16 0.9 layer1\n",
    "#B6 imagenet batch_size 16 0.926 layer2\n",
    "#B6 imagenet batch_size 16 0.94 layer3 # batch size OOM 32\n",
    "#B6 imagenet batch_size 16 0.85 layer4\n",
    "\n",
    "\n",
    "# ResNet50 batch_size 64 0.953(flip)\n",
    "# ResNet50 batch_size 64 0.966(random flip)\n",
    "# + rotate 5 0.98\n",
    "# + rotate 7 0.96\n",
    "# + rotate 10 0.953\n",
    "# ResNet50 batch_size 64 0.953(random flip + constrast_pil) -> 0.946\n",
    "# ResNet50 batch_size 64 0.94(random flip + constrast_cv) -> 0.946\n",
    "# ResNet50 batch_size 64 0.94(flip + constrast_pil) -> test 0.953\n",
    "# ResNet50 batch_size 64 0.926(flip + constrast_cv) -> test 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep001-val_loss0.708.h5\n",
      "0.7266666666666667\n",
      "ep002-val_loss0.565.h5\n",
      "0.8133333333333334\n",
      "ep003-val_loss0.903.h5\n",
      "0.76\n",
      "ep004-val_loss0.340.h5\n",
      "0.8933333333333333\n",
      "ep005-val_loss0.199.h5\n",
      "0.92\n",
      "ep006-val_loss0.207.h5\n",
      "0.9333333333333333\n",
      "ep007-val_loss0.197.h5\n",
      "0.9466666666666667\n",
      "ep008-val_loss0.151.h5\n",
      "0.9466666666666667\n",
      "ep009-val_loss0.120.h5\n",
      "0.9533333333333334\n",
      "ep010-val_loss0.162.h5\n",
      "0.9466666666666667\n",
      "ep011-val_loss0.219.h5\n",
      "0.9133333333333333\n",
      "ep012-val_loss0.158.h5\n",
      "0.96\n",
      "ep013-val_loss0.186.h5\n",
      "0.9333333333333333\n",
      "ep014-val_loss0.145.h5\n",
      "0.9533333333333334\n",
      "ep015-val_loss0.158.h5\n",
      "0.9533333333333334\n",
      "ep016-val_loss0.162.h5\n",
      "0.9533333333333334\n",
      "ep017-val_loss0.141.h5\n",
      "0.9533333333333334\n",
      "ep018-val_loss0.133.h5\n",
      "0.9533333333333334\n",
      "ep019-val_loss0.141.h5\n",
      "0.9533333333333334\n",
      "ep020-val_loss0.159.h5\n",
      "0.94\n",
      "ep021-val_loss0.160.h5\n",
      "0.9466666666666667\n",
      "ep022-val_loss0.163.h5\n",
      "0.9533333333333334\n",
      "ep023-val_loss0.164.h5\n",
      "0.9466666666666667\n",
      "ep024-val_loss0.135.h5\n",
      "0.9533333333333334\n",
      "ep025-val_loss0.157.h5\n",
      "0.9533333333333334\n",
      "ep026-val_loss0.144.h5\n",
      "0.9533333333333334\n",
      "ep027-val_loss0.119.h5\n",
      "0.96\n",
      "ep028-val_loss0.146.h5\n",
      "0.9533333333333334\n",
      "ep029-val_loss0.193.h5\n",
      "0.96\n",
      "ep030-val_loss0.160.h5\n",
      "0.9533333333333334\n",
      "ep031-val_loss0.176.h5\n",
      "0.94\n",
      "ep032-val_loss0.213.h5\n",
      "0.92\n",
      "ep033-val_loss0.226.h5\n",
      "0.9133333333333333\n",
      "ep034-val_loss0.185.h5\n",
      "0.9066666666666666\n",
      "ep035-val_loss0.200.h5\n",
      "0.9066666666666666\n",
      "ep036-val_loss0.207.h5\n",
      "0.9066666666666666\n",
      "ep037-val_loss0.214.h5\n",
      "0.9133333333333333\n",
      "ep038-val_loss0.215.h5\n",
      "0.9266666666666666\n",
      "ep039-val_loss0.179.h5\n",
      "0.9333333333333333\n",
      "ep040-val_loss0.142.h5\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "for log in sorted(os.listdir(f'./logs/')):\n",
    "    model.load_weights(f'logs/{log}')\n",
    "    print(log)\n",
    "    print(np.count_nonzero(np.argmax(model.predict(test_img), axis=1) == label_num) / num_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
